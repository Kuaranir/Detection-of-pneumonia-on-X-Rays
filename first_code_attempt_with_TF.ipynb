{"cells":[{"cell_type":"markdown","id":"d8bb0a49-8926-411e-aefc-43b107d90e86","metadata":{"id":"d8bb0a49-8926-411e-aefc-43b107d90e86"},"source":["<h1>Pneumonia detection using CNN+TensorFlow+Keras</h1>"]},{"cell_type":"code","source":["#! nvidia-smi --query"],"metadata":{"id":"hh7DDGSBhnh-"},"id":"hh7DDGSBhnh-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"dbdaf1e5-b7aa-4044-97d7-91426e0d2c45","metadata":{"id":"dbdaf1e5-b7aa-4044-97d7-91426e0d2c45"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","import yaml\n","import h5py\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.keras import models, layers, regularizers, optimizers, callbacks, metrics\n","from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n","from tensorflow.python.keras.utils.np_utils import to_categorical\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import confusion_matrix\n","%matplotlib inline\n","\n","config = yaml.safe_load(open('/content/drive/My Drive/X-Ray-pneumonia-with-CV/X-ray-parameters.yml', 'r'))"]},{"cell_type":"markdown","id":"4aaab713-afb3-4186-94fc-e427d3bbec7e","metadata":{"id":"4aaab713-afb3-4186-94fc-e427d3bbec7e","tags":[]},"source":["<h2>The original images preprocessing:</h2> "]},{"cell_type":"code","execution_count":null,"id":"4cfc0a49-7206-41d9-b4df-03eb765a4de0","metadata":{"id":"4cfc0a49-7206-41d9-b4df-03eb765a4de0"},"outputs":[],"source":["labels = ['NORMAL', 'PNEUMONIA']\n","\n","def get_data(data_dir):\n","    data = []\n","    for label in labels: \n","        path = os.path.join(data_dir, label)\n","        class_num = labels.index(label)\n","        for img in os.listdir(path):\n","            img_arr = cv2.imread(os.path.join(path, img))\n","            resized_arr = cv2.resize(img_arr, (config.get('img_size'), config.get('img_size'))) #Reshaping images to given size\n","            data.append([resized_arr, class_num])\n","    return np.array(data)"]},{"cell_type":"code","execution_count":null,"id":"3936687a-a711-46c2-b900-65fdd21d9c79","metadata":{"id":"3936687a-a711-46c2-b900-65fdd21d9c79"},"outputs":[],"source":["# Converting images to numpy arrays according to RGB format:\n","train = get_data('/content/drive/My Drive/X-Ray-pneumonia-with-CV/train')\n","val = get_data('/content/drive/My Drive/X-Ray-pneumonia-with-CV/val')\n","test = get_data('/content/drive/My Drive/X-Ray-pneumonia-with-CV/test')\n","\n","print('Train shape: ', train.shape)\n","print('Val shape: ', val.shape)\n","print('Test shape: ', test.shape);"]},{"cell_type":"markdown","id":"e8788824-1247-46d0-b819-f56848bf05c7","metadata":{"id":"e8788824-1247-46d0-b819-f56848bf05c7"},"source":["Every image has been converted as a np-array (224, 224, 3)"]},{"cell_type":"code","execution_count":null,"id":"a996e4be-9fa1-4f63-aec3-ce6c093cd9ea","metadata":{"id":"a996e4be-9fa1-4f63-aec3-ce6c093cd9ea"},"outputs":[],"source":["s = []\n","for i in train:\n","    if i[1] == 0:\n","        s.append('NORMAL')\n","    else:\n","        s.append('PNEUMONIA')\n","sns.countplot(s, linewidth = 1, edgecolor = sns.color_palette('dark', 1), palette = 'gnuplot2');"]},{"cell_type":"markdown","id":"948ed8bf-2362-4bf0-8d41-72aa04d8dda2","metadata":{"id":"948ed8bf-2362-4bf0-8d41-72aa04d8dda2"},"source":["Let's convert any images of both the classes backwards to RGB format and plot it:"]},{"cell_type":"code","execution_count":null,"id":"eb9b971b-a81b-4e54-9011-571bc04fded2","metadata":{"id":"eb9b971b-a81b-4e54-9011-571bc04fded2"},"outputs":[],"source":["import matplotlib\n","matplotlib.rcParams.update({'font.size': 16})\n","plt.figure(figsize = (10, 10))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(train[0][0], cmap = 'gray');\n","plt.title(labels[train[0][1]]);\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(train[1223][0], cmap = 'gray');\n","plt.title(labels[train[-1][1]]);"]},{"cell_type":"code","execution_count":null,"id":"dfbeb8c9-573d-459d-a6c8-4145819b8902","metadata":{"id":"dfbeb8c9-573d-459d-a6c8-4145819b8902"},"outputs":[],"source":["# Making train, val and test datasets with labels:\n","x_train = []\n","y_train = []\n","\n","x_val = []\n","y_val = []\n","\n","x_test = []\n","y_test = []\n","\n","for feature, label in train:\n","    x_train.append(feature)\n","    y_train.append(label)\n","\n","for feature, label in test:\n","    x_test.append(feature)\n","    y_test.append(label)\n","    \n","for feature, label in val:\n","    x_val.append(feature)\n","    y_val.append(label)\n","\n","# Normalizing the data in range from 0 to 1:\n","\n","x_train = np.asarray(x_train, dtype = 'float32') / 255\n","x_val = np.asarray(x_val, dtype = 'float32') / 255\n","x_test = np.asarray(x_test, dtype = 'float32') / 255\n","\n","y_train = to_categorical(y_train, len(labels))\n","y_val = to_categorical(y_val, len(labels))\n","y_test = to_categorical(y_test, len(labels))\n","\n","print('Train dataset shape:', x_train.shape)\n","print('Val dataset shape:', x_val.shape)\n","print('Test dataset shape:', x_test.shape)\n","\n","print('Train label shape:', y_train.shape)\n","print('Val label shape:', y_val.shape)\n","print('Test label shape:', y_test.shape)"]},{"cell_type":"markdown","id":"93306b0f-4a62-4ce5-93d5-8f255cdffeb1","metadata":{"id":"93306b0f-4a62-4ce5-93d5-8f255cdffeb1"},"source":["<h2>Data augmentation:</h2>"]},{"cell_type":"code","execution_count":null,"id":"82e22c6b-dbe1-4008-8c4b-df8d2341ca0b","metadata":{"id":"82e22c6b-dbe1-4008-8c4b-df8d2341ca0b"},"outputs":[],"source":["datagen = ImageDataGenerator(\n","    featurewise_center = False, # set input mean to 0 over the dataset, feature-wise\n","    samplewise_center = False, # set each sample mean to 0\n","    featurewise_std_normalization = False, # divide inputs by std of the dataset, feature-wise\n","    samplewise_std_normalization = False, # divide each input by its std\n","    zca_whitening = False, # applying ZCA whitening, is made specifically for images. It is like PCA for a tabular data.\n","    rotation_range = 60, # degree range for random rotations\n","    zoom_range = 0.2, # zooms image by 20 %\n","    width_shift_range = 0.1, # randomly shifts the image horizontally\n","    height_shift_range = 0.1, # randomly shifts the image vertically\n","    horizontal_flip = True, # randomly flips images horizontally\n","    vertical_flip = False) # randomly flips images vertically, we don't need it\n","datagen.fit(x_train)"]},{"cell_type":"markdown","id":"7e5beadb-f127-4c41-ab63-f1824e14d2ce","metadata":{"id":"7e5beadb-f127-4c41-ab63-f1824e14d2ce"},"source":["<h2>Building the model:</h2>"]},{"cell_type":"code","execution_count":null,"id":"d626de34-d88c-4f04-85c2-5a17eddbde5d","metadata":{"id":"d626de34-d88c-4f04-85c2-5a17eddbde5d"},"outputs":[],"source":["model = tf.keras.applications.resnet.ResNet152(\n","    include_top = True, weights = None, input_tensor = None,\n","    input_shape = (config.get('img_size'), config.get('img_size'), 3),\n","    pooling = 'max', classes = 2,\n","    classifier_activation = 'sigmoid')\n","\n","model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","              optimizer = tf.keras.optimizers.Adam(lr = config.get('learning_rate')),\n","              metrics = [metrics.BinaryAccuracy(),\n","                         metrics.Recall(),\n","                         metrics.Precision()])\n","\n","'''Since we have to diagnose pneumonia, quite serious disease, we should to monitor FalseNegative metric and minimize it,\n","because diagnosing a sick person as a healthy is a huge mistake unlike diagnosing a healthy person as sick.\n","Therefore, Recall is our goal metric.'''\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"id":"21aca171-5001-484c-8186-36a78d328e23","metadata":{"id":"21aca171-5001-484c-8186-36a78d328e23"},"outputs":[],"source":["#Plotting the model as a graph:\n","#plot_model(model, show_shapes = True, to_file = 'model_plot.png')"]},{"cell_type":"markdown","id":"7454e7ed-52fa-4b21-94c7-d96efe9443a8","metadata":{"id":"7454e7ed-52fa-4b21-94c7-d96efe9443a8"},"source":["<h2>Callbacks:</h2>"]},{"cell_type":"code","execution_count":null,"id":"eca46cee-3a5d-4718-abc0-7c5c3aa6c93a","metadata":{"id":"eca46cee-3a5d-4718-abc0-7c5c3aa6c93a"},"outputs":[],"source":["# Callbacks:\n","learning_rate_reduction = callbacks.ReduceLROnPlateau(\n","    monitor = 'val_binary_accuracy', # tracing validation's accuracy\n","    factor = 0.1, # decreasing learning rate by 10 times\n","    patience = 2, # number of epochs with no loss improvement. By this number callback is called\n","    verbose = 1, # updating messages\n","    min_lr = 0.000001) # lower bound on the learning rate\n","\n","tensorboard = callbacks.TensorBoard(\n","    log_dir = '/content/drive/My Drive/X-Ray-pneumonia-with-CV', # the path of the directory where to save the log files to be parsed by TensorBoard\n","    histogram_freq = 1,\n","    write_graph = True,\n","    embeddings_freq = 1) # frequency (in epochs) at which embedding layers will be visualized\n","\n","model_checkpoint = callbacks.ModelCheckpoint(\n","    filepath = '/content/drive/My Drive/X-Ray-pneumonia-with-CV/X-Ray-modelcheckpoint.h5', # path to save the model file\n","    monitor = 'val_loss', # model metric to monitor\n","    mode = 'auto', # replacing filepath with a new best model\n","    save_best_only = True) # this callback will save the best model\n","\n","Callbacks = [learning_rate_reduction, tensorboard, model_checkpoint]"]},{"cell_type":"code","execution_count":null,"id":"85cecf8f-6907-41d5-9de5-344694548859","metadata":{"id":"85cecf8f-6907-41d5-9de5-344694548859"},"outputs":[],"source":["history = model.fit(datagen.flow(x_train, y_train),\n","                    batch_size = config.get('batch_size'),\n","                    epochs = config.get('epochs'),\n","                    shuffle = True,\n","                    validation_data = datagen.flow(x_val, y_val),\n","                    callbacks = Callbacks)"]},{"cell_type":"code","execution_count":null,"id":"9d26a9f0-f488-438b-9a5f-604b589c4aa5","metadata":{"id":"9d26a9f0-f488-438b-9a5f-604b589c4aa5"},"outputs":[],"source":["print('Accuracy of the model is: {:.2f}'.format(model.evaluate(x_test, y_test)[1]))\n","print('Recall of the model is: {:.2f}'.format(model.evaluate(x_test, y_test)[3]))"]},{"cell_type":"code","execution_count":null,"id":"7102f619-a50d-413a-9759-74cde4b7b00c","metadata":{"id":"7102f619-a50d-413a-9759-74cde4b7b00c"},"outputs":[],"source":["#Loss and accuracy graphs:\n","history_dict = history.history\n","epochs = range(1, len(history_dict['binary_accuracy']) + 1)\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","\n","plt.figure(figsize = (55, 7))\n","plt.subplot(1, 2, 1)\n","\n","plt.plot(epochs, loss_values, 'ro', label = 'Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize = (55, 7))\n","\n","plt.subplot(1, 2, 2)\n","acc_values = history_dict['binary_accuracy']\n","val_acc_values = history_dict['val_binary_accuracy']\n","plt.plot(epochs, acc_values, 'ro', label = 'Training_acc')\n","plt.plot(epochs, val_acc_values, 'b', label = 'Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"09603bf9-e2e7-410e-9391-b10857355023","metadata":{"id":"09603bf9-e2e7-410e-9391-b10857355023"},"outputs":[],"source":["trained_model = models.load_model('/content/drive/My Drive/X-Ray-pneumonia-with-CV/X-Ray-modelcheckpoint.h5')"]},{"cell_type":"code","execution_count":null,"id":"a44712bc-4e90-43e5-86f4-e101b9814d3a","metadata":{"id":"a44712bc-4e90-43e5-86f4-e101b9814d3a"},"outputs":[],"source":["print('Accuracy of the model is: {:.2f}'.format(trained_model.evaluate(x_test, y_test)[1]))\n","print('Recall of the model is: {:.2f}'.format(trained_model.evaluate(x_test, y_test)[3]))"]},{"cell_type":"code","source":["# Plotting confusion matrix:\n","from sklearn.metrics import confusion_matrix\n","import matplotlib\n","matplotlib.rcParams.update({'font.size': 18})\n","\n","pred = trained_model.predict(x_test)\n","pred = np.argmax(pred, axis = 1)\n","y_true = np.argmax(y_test, axis = 1)\n","\n","cm = confusion_matrix(y_true, pred)\n","from mlxtend.plotting import plot_confusion_matrix\n","fig, ax = plot_confusion_matrix(conf_mat = cm, figsize = (7, 7))\n","plt.itle('Confusion matrix:')\n","plt.show()"],"metadata":{"id":"_EzAMjLG0U3_"},"id":"_EzAMjLG0U3_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h4>Conclusion: \n","I have attempted to train ResNet152 ('out the box'), with 100 epochs. ResNet152 has been trained about 2 hours 30 minutes. \n","I have obtained validation recall = 97 % and test recall = 88 %. Despite of augmentation and large amount of epochs, along with confusion matrix it means overfitting.\n","\n","Therefore, I have decided to revise my model and architecture and take a different approach.</h4>"],"metadata":{"id":"EnZhKHq2F0v3"},"id":"EnZhKHq2F0v3"},{"cell_type":"code","source":[""],"metadata":{"id":"3Bs7S6wtEnoN"},"id":"3Bs7S6wtEnoN","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"X-Ray-my-first-attempt.ipynb","provenance":[{"file_id":"1ukkjT08AVVaMgV1Ee74rvRT5OEZk2hYX","timestamp":1642100000497}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":5}